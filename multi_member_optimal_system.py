import subprocess
import cv2
import numpy as np
import os
from PIL import Image, ImageDraw, ImageFont
from scipy import interpolate
from scipy.ndimage import gaussian_filter1d

def put_korean_text(img, text, position, font_size=30, color=(255, 255, 255)):
    #í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ì¶”ê°€
    try:
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        try:
            font = ImageFont.truetype("malgun.ttf", font_size)
        except:
            try:
                font = ImageFont.truetype("C:/Windows/Fonts/malgun.ttf", font_size)
            except:
                font = ImageFont.load_default()
        
        color_rgb = (color[2], color[1], color[0])  # BGR â†’ RGB
        bbox = draw.textbbox(position, text, font=font) # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        draw.rectangle(bbox, fill=(0, 0, 0, 180)) # ë°˜íˆ¬ëª… ë°°ê²½ ì¶”ê°€
        draw.text(position, text, font=font, fill=color_rgb) 
        
        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        return img_cv
    except Exception as e:
        print(f"í•œê¸€ í…ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        cv2.putText(img, text.encode('ascii', 'ignore').decode('ascii'), 
                position, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        return img

def select_multiple_members(video_path):
    """6ëª…ê¹Œì§€ ìˆœì„œëŒ€ë¡œ ë“œë˜ê·¸ ì„ íƒ (ì´ë¦„ ì§ì ‘ ì…ë ¥)"""
    print("ìµœì†Œ 1ëª… ë¶€í„° ìµœëŒ€ 6ëª…ì˜ ë©¤ë²„ë¥¼ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì„¸ìš”")
    print("ì‚¬ìš©ë²•:")
    print("   1. í„°ë¯¸ë„ì—ì„œ ìŠ¬ë¡¯ ë²ˆí˜¸ ì…ë ¥ (1~6)")
    print("   2. ë©¤ë²„ ì´ë¦„ ì…ë ¥")
    print("   3. í•´ë‹¹ ë©¤ë²„ë¥¼ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸(ì „ì‹ ì„ ë“œë˜ê·¸ í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.)")
    print("   4. Enterë¡œ í™•ì¸, ë‹¤ìŒ ë©¤ë²„ ì„ íƒ")
    print("   5. 'q' ì…ë ¥ì‹œ ì„ íƒ ì™„ë£Œ(ì‹¤í–‰)")
    
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print("ë¹„ë””ì˜¤ ì½ê¸° ì‹¤íŒ¨")
        return {}
    
    print(f"Video size: {frame.shape[1]}x{frame.shape[0]}")
    
    # ìƒ‰ìƒ ì •ë³´ (6ê°œ ìŠ¬ë¡¯)
    slot_colors = [
        (0, 0, 255),      # ë¹¨ê°„ìƒ‰
        (0, 165, 255),    # ì£¼í™©ìƒ‰
        (0, 255, 255),    # ë…¸ë€ìƒ‰
        (0, 255, 0),      # ì´ˆë¡ìƒ‰
        (255, 0, 0),      # íŒŒë€ìƒ‰
        (255, 0, 255),    # ë³´ë¼ìƒ‰
    ]
    
    color_names = ["ë¹¨ê°„ìƒ‰", "ì£¼í™©ìƒ‰", "ë…¸ë€ìƒ‰", "ì´ˆë¡ìƒ‰", "íŒŒë€ìƒ‰", "ë³´ë¼ìƒ‰"]
    
    selected_members = {}
    used_slots = set()
    display_frame = frame.copy()
    
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ìƒ‰ìƒ ìŠ¬ë¡¯:")
    for i, color_name in enumerate(color_names):
        print(f"   {i+1}. {color_name}")
    
    while len(selected_members) < 6:
        print(f"\ní˜„ì¬ ì„ íƒëœ ë©¤ë²„: {len(selected_members)}/6ëª…")
        # ì‚¬ìš©ëœê±° í‘œê¸°
        used_slots_display = [slot + 1 for slot in sorted(used_slots)] if used_slots else []
        print(f"ì‚¬ìš©ëœ ìŠ¬ë¡¯: {used_slots_display if used_slots_display else 'ì—†ìŒ'}")
        
        # ìŠ¬ë¡¯ ë²ˆí˜¸ ì…ë ¥
        while True:  # ìŠ¬ë¡¯ ì„ íƒ ë£¨í”„
            try:
                user_input = input(f"ìƒ‰ìƒ ìŠ¬ë¡¯ ë²ˆí˜¸ ì…ë ¥ (1-6) ë˜ëŠ” 'q'ë¡œ ì™„ë£Œ: ").strip()
                
                if user_input.lower() == 'q':
                    return selected_members  # í•¨ìˆ˜ ì¢…ë£Œ
                    
                slot_idx = int(user_input) - 1
                
                if slot_idx < 0 or slot_idx >= 6:
                    print("âŒ 1~6 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                    continue
                    
                if slot_idx in used_slots:
                    # ê¸°ì¡´ ë©¤ë²„ ì •ë³´ ì°¾ê¸°
                    existing_member = None
                    for name, info in selected_members.items():
                        if info['slot_index'] == slot_idx:
                            existing_member = name
                            break
                    
                    print(f"âŒ {slot_idx + 1}ë²ˆ ìŠ¬ë¡¯({color_names[slot_idx]})ì€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
                    if existing_member:
                        print(f"   í˜„ì¬ í• ë‹¹ëœ ë©¤ë²„: {existing_member}")
                    
                    retry = input("ê¸°ì¡´ ì„ íƒì„ ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ?(Y/N): ").strip().upper()
                    if retry == 'Y':
                        # ê¸°ì¡´ ë©¤ë²„ ì œê±°
                        if existing_member:
                            del selected_members[existing_member]
                            used_slots.remove(slot_idx)
                            print(f"âœ… {existing_member} ì„ íƒì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            # display_frameì„ ë‹¤ì‹œ ê·¸ë¦¬ê¸° (ì œê±°ëœ ë°•ìŠ¤ ë°˜ì˜)
                            display_frame = frame.copy()
                            for remaining_name, remaining_info in selected_members.items():
                                x, y, w, h = remaining_info['bbox']
                                remaining_color = remaining_info['color']
                                cv2.rectangle(display_frame, (x, y), (x+w, y+h), remaining_color, 3)
                                display_frame = put_korean_text(display_frame, remaining_name, (x, y-35), 
                                                                font_size=24, color=remaining_color)
                        
                        break  # ê°™ì€ ìŠ¬ë¡¯ìœ¼ë¡œ ìƒˆë¡œ ì„ íƒ ì§„í–‰
                    elif retry == 'N':
                        slot_idx = None  # ìŠ¬ë¡¯ ì„ íƒ ê±´ë„ˆë›°ê¸° í‘œì‹œ
                        break  # ìŠ¬ë¡¯ ì„ íƒ ë£¨í”„ íƒˆì¶œ
                    else:
                        print("Y ë˜ëŠ” Nì„ ì…ë ¥í•˜ì„¸ìš”")
                        continue
                else:
                    break  # ìœ íš¨í•œ ìŠ¬ë¡¯ ì„ íƒë¨
                    
            except ValueError:
                print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                continue
            except KeyboardInterrupt:
                print("\nâŒ ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
                return {}
        
        # Nì„ ì„ íƒí•´ì„œ ìŠ¬ë¡¯ ì„ íƒì„ ê±´ë„ˆë›´ ê²½ìš°
        if slot_idx is None:
            continue
        
        # ë©¤ë²„ ì´ë¦„ ì…ë ¥
        try:
            member_name = input(f"{color_names[slot_idx]} ìŠ¬ë¡¯ì— í• ë‹¹í•  ë©¤ë²„ ì´ë¦„: ").strip()
            
            if not member_name:
                print("âŒ ë©¤ë²„ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”")
                continue
                
            if member_name in selected_members:
                print(f"âŒ '{member_name}'ì€ ì´ë¯¸ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
                continue
                
        except KeyboardInterrupt:
            print("\nâŒ ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            return {}
        
        # ìƒ‰ìƒ ì •ë³´
        color = slot_colors[slot_idx]
        color_name = color_names[slot_idx]
        
        print(f"\n {member_name} ({color_name} ìŠ¬ë¡¯)ì„ ë§ˆìš°ìŠ¤ë¡œ ë“œë˜ê·¸í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”...")
        
        # 20% ì¶•ì†Œë¡œ ì°½ í‘œì‹œí•˜ê³  ìœ„ì¹˜ ì¡°ì •
        new_width = int(frame.shape[1] * 0.8)  # 80% í¬ê¸° (20% ì¶•ì†Œ)
        new_height = int(frame.shape[0] * 0.8)
        display_small = cv2.resize(display_frame, (new_width, new_height))
        
        # í•œê¸€ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ ì˜ì–´ë¡œ ì°½ ì œëª© ì„¤ì •
        window_name = f"Member Selection_Slot"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, new_width, new_height)
        cv2.moveWindow(window_name, 100, 50)  # í™”ë©´ ìœ„ìª½ìœ¼ë¡œ ì´ë™
        
        # ì›ë³¸ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ROI ì„ íƒ (í™”ë©´ì€ ì‘ê²Œ í‘œì‹œí•˜ì§€ë§Œ ì¢Œí‘œëŠ” ì›ë³¸ ê¸°ì¤€)
        bbox = cv2.selectROI(window_name, display_frame, False, False)
        cv2.destroyAllWindows()
        
        if bbox[2] > 0 and bbox[3] > 0:
            selected_members[member_name] = {
                'bbox': bbox,
                'color': color,
                'color_name': color_name,
                'slot_index': slot_idx
            }
            
            used_slots.add(slot_idx)
            
            # ì„ íƒëœ ë°•ìŠ¤ë¥¼ display_frameì— ê·¸ë¦¬ê¸°
            x, y, w, h = bbox
            cv2.rectangle(display_frame, (x, y), (x+w, y+h), color, 3)
            
            # ë©¤ë²„ ì´ë¦„ ì¶”ê°€
            display_frame = put_korean_text(display_frame, member_name, (x, y-35), 
                                        font_size=24, color=color)
            
            print(f"âœ… {member_name} ({color_name}) ì„ íƒë¨: {bbox}")
        else:
            print(f"âŒ {member_name} ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
    
    print(f"\nğŸ“Š ìµœì¢… ì„ íƒ: {len(selected_members)}ëª…")
    for name, info in selected_members.items():
        print(f"   {name}: {info['color_name']} ìŠ¬ë¡¯ {info['bbox']}")
    
    return selected_members

def create_bbox_file(bbox, filename):
    # ë°”ìš´ë”©ë°•ìŠ¤ íŒŒì¼ ìƒì„±
    x, y, w, h = bbox
    with open(filename, 'w') as f:
        f.write(f"{x},{y},{w},{h}")

def run_single_tracking(video_path, bbox_file, model_path, output_path): 
    # SAMURAI ì¶”ì  ì‹¤í–‰
    cmd = [
        "python", "scripts/demo.py",
        "--video_path", video_path,
        "--txt_path", bbox_file,
        "--model_path", model_path,
        "--video_output_path", output_path
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        return True
    else:
        print(f"âŒ ì¶”ì  ì‹¤íŒ¨: {result.stderr}")
        return False

def extract_center_coords(tracked_video, original_video):
    # ì „ì²´ ê²½ë¡œ ì¶”ì¶œ
    original_cap = cv2.VideoCapture(original_video)
    tracked_cap = cv2.VideoCapture(tracked_video)
    
    center_coords = []
    frame_count = 0
    valid_detections = 0
    
    while True:
        ret_orig, orig_frame = original_cap.read()
        ret_track, track_frame = tracked_cap.read()
        
        if not ret_orig or not ret_track:
            break
        
        frame_count += 1
        
        if track_frame.shape[:2] != orig_frame.shape[:2]:
            track_frame = cv2.resize(track_frame, (orig_frame.shape[1], orig_frame.shape[0]))
        
        diff = cv2.absdiff(track_frame, orig_frame)
        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
        _, mask = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)
        
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            largest = max(contours, key=cv2.contourArea)
            if cv2.contourArea(largest) > 500:
                x, y, w, h = cv2.boundingRect(largest)
                body_start_y = y + int(h * 0.15)  
                body_end_y = y + int(h * 0.75)    
                body_center_y = (body_start_y + body_end_y) // 2
                body_center_x = x + w // 2
                
                center_coords.append((body_center_x, body_center_y))
                valid_detections += 1
            else:
                center_coords.append(None)
        else:
            center_coords.append(None)
    
    original_cap.release()
    tracked_cap.release()
    
    return center_coords

def interpolate_missing_positions(center_coords):
    #ëˆ„ë½ëœ ìœ„ì¹˜ ë³´ê°„
    valid_indices = []
    valid_x = []
    valid_y = []
    
    for i, coord in enumerate(center_coords):
        if coord is not None:
            valid_indices.append(i)
            valid_x.append(coord[0])
            valid_y.append(coord[1])
    
    if len(valid_indices) < 2:
        return center_coords
    
    all_indices = np.arange(len(center_coords))
    interp_x = np.interp(all_indices, valid_indices, valid_x)
    interp_y = np.interp(all_indices, valid_indices, valid_y)
    
    interpolated_coords = [(int(x), int(y)) for x, y in zip(interp_x, interp_y)]
    return interpolated_coords

def calculate_optimal_camera_path(center_coords, crop_width=400, crop_height=750):
    #ìµœì  ì¹´ë©”ë¼ ê²½ë¡œ ê³„ì‚°
    interpolated_coords = interpolate_missing_positions(center_coords)
    
    x_coords = np.array([coord[0] for coord in interpolated_coords])
    y_coords = np.array([coord[1] for coord in interpolated_coords])
    
    smoothing_sigma = 8.0
    
    try:
        smooth_x = gaussian_filter1d(x_coords, sigma=smoothing_sigma)
        smooth_y = gaussian_filter1d(y_coords, sigma=smoothing_sigma)
    except:
        smooth_x = x_coords
        smooth_y = y_coords
    
    TOP_MARGIN = 100 #ìƒë‹¨ ì—¬ë°±(ë¨¸ë¦¬)
    BOTTOM_MARGIN = 120 #í•˜ë‹¨ ì—¬ë°±(ë°œ)
    
    camera_x = smooth_x
    camera_y = smooth_y + BOTTOM_MARGIN - TOP_MARGIN 
    
    optimal_path = [(int(x), int(y)) for x, y in zip(camera_x, camera_y)] # ì •ìˆ˜ ì¢Œí‘œë¡œ ë³€í™˜
    return optimal_path 

def create_optimal_cropped_video(original_video, optimal_camera_path, output_path, member_name, crop_width=400, crop_height=750):
    #ê°œì¸ í¬ë¡­ ì˜ìƒ ìƒì„±
    print(f"{member_name} ìµœì í™”ëœ í¬ë¡­ ì˜ìƒ ìƒì„± ì¤‘")
    
    cap = cv2.VideoCapture(original_video) 
    fps = cap.get(cv2.CAP_PROP_FPS)
    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (crop_width, crop_height))
    
    frame_idx = 0
    
    while True:
        ret, frame = cap.read() 
        if not ret:
            break
        
        if frame_idx < len(optimal_camera_path): 
            cam_x, cam_y = optimal_camera_path[frame_idx]
            
            start_x = max(0, cam_x - crop_width // 2)
            start_y = max(0, cam_y - crop_height // 2)
            
            if start_x + crop_width > orig_width:
                start_x = orig_width - crop_width
            if start_y + crop_height > orig_height:
                start_y = orig_height - crop_height
            
            start_x = max(0, start_x)
            start_y = max(0, start_y)
            
            end_x = start_x + crop_width
            end_y = start_y + crop_height
            
            cropped_frame = frame[start_y:end_y, start_x:end_x]
            
            if cropped_frame.shape[:2] != (crop_height, crop_width):
                padded_frame = np.zeros((crop_height, crop_width, 3), dtype=np.uint8)
                h, w = cropped_frame.shape[:2]
                padded_frame[:h, :w] = cropped_frame
                cropped_frame = padded_frame
                
        else:
            cropped_frame = np.zeros((crop_height, crop_width, 3), dtype=np.uint8)
        
        out.write(cropped_frame)
        frame_idx += 1
        
        if frame_idx % 60 == 0:
            print(f"{member_name}: {frame_idx} frames processed...")
    
    cap.release()
    out.release()
    print(f"âœ… {member_name} í¬ë¡­ ì˜ìƒ ì™„ë£Œ: {output_path}")

def create_full_view_with_crop_boxes(original_video, all_camera_paths, member_info, output_path, crop_width=400, crop_height=750): 
    #ì „ì²´ ì˜ìƒì— ê° ë©¤ë²„ì˜ í¬ë¡­ ë°•ìŠ¤ í‘œì‹œ
    print(f"ì „ì²´ ì˜ìƒì— í¬ë¡­ ë°•ìŠ¤ í‘œì‹œ ìƒì„± ì¤‘...")
    
    cap = cv2.VideoCapture(original_video)
    fps = cap.get(cv2.CAP_PROP_FPS)
    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
    out = cv2.VideoWriter(output_path, fourcc, fps, (orig_width, orig_height)) 
    
    frame_idx = 0 # í”„ë ˆì„ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
    
    print(f"ì „ì²´ ë°•ìŠ¤ ì˜ìƒ ìƒì„±")
    print(f"   ì›ë³¸ í¬ê¸° ìœ ì§€: {orig_width}x{orig_height}")
    print(f"   ê° ë©¤ë²„ë³„ í¬ë¡­ ë°•ìŠ¤ ì‹¤ì‹œê°„ í‘œì‹œ")
    print(f"   ë©¤ë²„ë³„ ê³ ìœ  ìƒ‰ìƒ ë°•ìŠ¤")
    print(f"   ì¹´ë©”ë¼ê°€ ì‹¤ì œë¡œ í¬ë¡­í•˜ëŠ” ì˜ì—­ ì‹œê°í™”")
    print(f"   ì„ íƒëœ ë©¤ë²„: {', '.join(member_info.keys())}")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        result_frame = frame.copy()
        
        # ê° ë©¤ë²„ì˜ í¬ë¡­ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for member_name, info in member_info.items():
            if member_name in all_camera_paths:
                camera_path = all_camera_paths[member_name]
                
                if frame_idx < len(camera_path):
                    cam_x, cam_y = camera_path[frame_idx]
                    color = info['color']
                    
                    # í¬ë¡­ ë°•ìŠ¤ ê³„ì‚°
                    box_x = max(0, cam_x - crop_width // 2)
                    box_y = max(0, cam_y - crop_height // 2)
                    
                    if box_x + crop_width > orig_width:
                        box_x = orig_width - crop_width
                    if box_y + crop_height > orig_height:
                        box_y = orig_height - crop_height
                    
                    box_x = max(0, box_x)
                    box_y = max(0, box_y)
                    
                    # í¬ë¡­ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                    cv2.rectangle(result_frame, 
                                (box_x, box_y), 
                                (box_x + crop_width, box_y + crop_height), 
                                color, 4)
                    
                    # ë©¤ë²„ ì´ë¦„ ë¼ë²¨ ì¶”ê°€ (ì–´ë–¤ ì–¸ì–´ë“  ê°€ëŠ¥)
                    result_frame = put_korean_text(result_frame, member_name, 
                                                (box_x, box_y - 50), font_size=28, color=color)
                    
                    # ë°•ìŠ¤ ë‚´ë¶€ì— ë°˜íˆ¬ëª… ìƒ‰ìƒ ì˜¤ë²„ë ˆì´ (ì„ íƒì‚¬í•­)
                    overlay = result_frame.copy()
                    cv2.rectangle(overlay, (box_x, box_y), (box_x + crop_width, box_y + crop_height), 
                                color, -1)
                    result_frame = cv2.addWeighted(result_frame, 0.95, overlay, 0.05, 0)
        
        out.write(result_frame)
        frame_idx += 1
        
        if frame_idx % 60 == 0:
            progress = (frame_idx / frame_count) * 100
            print(f"   {frame_idx}/{frame_count} frames ({progress:.1f}%)...")
    
    cap.release()
    out.release()
    print(f"âœ… ì „ì²´ ë°•ìŠ¤ ì˜ìƒ ì™„ë£Œ: {output_path}")

def select_video_file():
    #ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ
    print("ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ")
    print("=" * 50)
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
    video_files = []
    
    try:
        for file in os.listdir('.'):
            if any(file.lower().endswith(ext) for ext in video_extensions):
                video_files.append(file)
    except:
        pass
    
    if video_files:
        print("í˜„ì¬ í´ë”ì˜ ë¹„ë””ì˜¤ íŒŒì¼:")
        for i, file in enumerate(video_files, 1):
            file_size = os.path.getsize(file) / (1024*1024)  # MB
            print(f"   {i}. {file} ({file_size:.1f} MB)")
        
        print(f"   {len(video_files) + 1}. ì§ì ‘ íŒŒì¼ ê²½ë¡œ ì…ë ¥")
        print("   q. ì¢…ë£Œ")
        
        while True: # íŒŒì¼ ì„ íƒ ë£¨í”„ 
            try:
                choice = input(f"\níŒŒì¼ ì„ íƒ (1-{len(video_files) + 1}) ë˜ëŠ” 'q': ").strip()
                
                if choice.lower() == 'q':
                    return None
                
                choice_num = int(choice)
                # ì„ íƒëœ ë²ˆí˜¸ê°€ ìœ íš¨í•œì§€ í™•ì¸
                if 1 <= choice_num <= len(video_files):
                    selected_file = video_files[choice_num - 1]
                    print(f"ì„ íƒëœ íŒŒì¼: {selected_file}")
                    return selected_file
                
                elif choice_num == len(video_files) + 1:
                    # ì§ì ‘ ê²½ë¡œ ì…ë ¥
                    break
                
                else:
                    print(f"âŒ 1~{len(video_files) + 1} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                    
            except ValueError:
                print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            except KeyboardInterrupt:
                print("\nâŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
                return None
    
    # ì§ì ‘ íŒŒì¼ ê²½ë¡œ ì…ë ¥
    while True:
        try:
            file_path = input("\në¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if not file_path:
                print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                continue
            
            # ë”°ì˜´í‘œ ì œê±° (ë“œë˜ê·¸&ë“œë¡­ì‹œ ìë™ ì¶”ê°€ë˜ëŠ” ê²½ìš°)
            file_path = file_path.strip('"').strip("'")
            
            if not os.path.exists(file_path):
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                continue
            
            # ë¹„ë””ì˜¤ íŒŒì¼ì¸ì§€ í™•ì¸
            if not any(file_path.lower().endswith(ext) for ext in video_extensions):
                print(f"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤")
                print(f"   ì§€ì› í˜•ì‹: {', '.join(video_extensions)}")
                continue
            
            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(file_path) / (1024*1024)  # MB
            print(f"âœ… ì„ íƒëœ íŒŒì¼: {file_path}")
            print(f"íŒŒì¼ í¬ê¸°: {file_size:.1f} MB")
            
            return file_path
            
        except KeyboardInterrupt:
            print("\nâŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
            return None
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    try:
        from scipy import interpolate
        from scipy.ndimage import gaussian_filter1d
        print("âœ… SciPy ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ë¨")
    except ImportError:
        print("âŒ SciPyê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì„¤ì¹˜ í•„ìš”: pip install scipy")
        return
    
    print("ë©€í‹° ì•„ì´ëŒ ìµœì  ì¹´ë©”ë¼ ì‹œìŠ¤í…œ")
    print("=" * 80)
    
    # ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ
    video_path = select_video_file()
    if not video_path:
        print("âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return
    
    # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps if fps > 0 else 0
    cap.release()
    
    # ì„¤ì •
    model_path = "checkpoints/sam2.1_hiera_base_plus.pt"
    
    FIXED_CROP_WIDTH = 400 # ê³ ì • í¬ë¡­ ë„ˆë¹„
    FIXED_CROP_HEIGHT = 750 # ê³ ì • í¬ë¡­ ë†’ì´
    
    print(f"í•´ìƒë„: {width}x{height}")
    print(f"ì˜ìƒ ê¸¸ì´: {duration:.1f}ì´ˆ ({frame_count} frames, {fps:.1f} fps)")
    print(f"Model: {model_path}")
    print(f"Crop Size: {FIXED_CROP_WIDTH}x{FIXED_CROP_HEIGHT}")
    print("ì¶œë ¥:")
    print(" 1. ì „ì²´ ì˜ìƒ + ê° ë©¤ë²„ í¬ë¡­ ë°•ìŠ¤ í‘œì‹œ")
    print(" 2. ê° ë©¤ë²„ë³„ ê°œì¸ ìµœì í™” í¬ë¡­ ì˜ìƒ")
    print("=" * 80)
    
    # Step 1: ë©¤ë²„ ì„ íƒ (ì´ë¦„ ì…ë ¥)
    print(f"\nStep 1: ë©¤ë²„ ì„ íƒ (ì´ë¦„ ì…ë ¥)")
    selected_members = select_multiple_members(video_path)
    
    if len(selected_members) == 0:
        print("âŒ ì„ íƒëœ ë©¤ë²„ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    print(f"\nì„ íƒëœ ë©¤ë²„: {len(selected_members)}ëª…")
    
    # Step 2: ê° ë©¤ë²„ë³„ ì¶”ì  ë° ê²½ë¡œ ê³„ì‚°
    all_camera_paths = {}
    temp_files = []
    
    for member_name, info in selected_members.items():
        print(f"\nğŸ¬ {member_name} ({info['color_name']}) ì²˜ë¦¬ ì¤‘...")
        
        # ë°”ìš´ë”©ë°•ìŠ¤ íŒŒì¼ ìƒì„±
        bbox_file = f"{member_name}_bbox.txt"
        create_bbox_file(info['bbox'], bbox_file)
        temp_files.append(bbox_file)
        
        # ì¶”ì  ì‹¤í–‰
        tracked_file = f"{member_name}_tracked.mp4"
        print(f"SAMURAI ì¶”ì  ì¤‘")
        
        if run_single_tracking(video_path, bbox_file, model_path, tracked_file):
            temp_files.append(tracked_file)
            
            # ê²½ë¡œ ì¶”ì¶œ
            print(f"ê²½ë¡œ ì¶”ì¶œ ì¤‘")
            center_coords = extract_center_coords(tracked_file, video_path)
            
            # ìµœì  ì¹´ë©”ë¼ ê²½ë¡œ ê³„ì‚°
            print(f"ìµœì  ê²½ë¡œ ê³„ì‚° ì¤‘")
            optimal_path = calculate_optimal_camera_path(center_coords, FIXED_CROP_WIDTH, FIXED_CROP_HEIGHT)
            all_camera_paths[member_name] = optimal_path
            
            # ê°œì¸ í¬ë¡­ ì˜ìƒ ìƒì„±
            crop_output = f"{member_name}_optimal_crop.mp4"
            create_optimal_cropped_video(video_path, optimal_path, crop_output, member_name, 
                                        FIXED_CROP_WIDTH, FIXED_CROP_HEIGHT)
        else:
            print(f"   âŒ {member_name} ì¶”ì  ì‹¤íŒ¨")
    
    # Step 3: ì „ì²´ ì˜ìƒì— í¬ë¡­ ë°•ìŠ¤ í‘œì‹œ
    if len(all_camera_paths) > 0:
        print(f"\nì „ì²´ ì˜ìƒì— í¬ë¡­ ë°•ìŠ¤ í‘œì‹œ ìƒì„± ì¤‘")
        create_full_view_with_crop_boxes(video_path, all_camera_paths, selected_members, 
                                        "Full_View_With_Crop_Boxes.mp4", 
                                        FIXED_CROP_WIDTH, FIXED_CROP_HEIGHT)
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    print(f"\nì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘")
    for temp_file in temp_files:
        if os.path.exists(temp_file):
            os.remove(temp_file)
    
    print("\n" + "=" * 80)
    print("ë©€í‹° ì•„ì´ëŒ ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print("ìƒì„±ëœ ì˜ìƒ:")
    print("Full_View_With_Crop_Boxes.mp4 (ì „ì²´ + í¬ë¡­ ë°•ìŠ¤)")
    for member_name in selected_members.keys():
        print(f"{member_name}_optimal_crop.mp4 (ê°œì¸ í¬ë¡­)")
    print("=" * 80)

if __name__ == "__main__":
    main()